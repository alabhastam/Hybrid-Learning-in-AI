{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":982,"sourceType":"datasetVersion","datasetId":483}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"background-color:#121212;color:#e0e0e0;font-family:Arial,Helvetica,sans-serif;padding:20px;line-height:1.6;\">\n  <h1 style=\"color:#ff9800;margin-bottom:10px;\">📚 Hybrid Learning in AI — SMS Spam Example</h1>\n\n  <p style=\"margin-bottom:15px;\">\n    <strong style=\"color:#4fc3f7;\">Hybrid Learning</strong> combines two or more approaches to build a stronger AI system.\n    It blends the strengths of different methods, making them work together — much like combining a calculator’s speed 🖩 with a human’s judgment 🧠.\n  </p>\n\n  <h2 style=\"color:#ffcc80;margin-top:20px;\">🔹 Why Use Hybrid Learning?</h2>\n  <ul style=\"margin-left:20px;margin-bottom:15px;\">\n    <li>Better accuracy through synergy of techniques.</li>\n    <li>Greater robustness against noisy or unexpected data.</li>\n    <li>Flexibility — choose the right tool for the right part of the task.</li>\n  </ul>\n\n  <h2 style=\"color:#ffcc80;margin-top:20px;\">🔹 Real-World Examples</h2>\n  <ul style=\"margin-left:20px;margin-bottom:15px;\">\n    <li>Bank fraud detection using Neural Networks + Rule-based checks.</li>\n    <li>Search engines combining Transformer NLP + TF-IDF ranking.</li>\n    <li>Medical imaging with CNN predictions + doctor-verified rules.</li>\n    <li>AI games blending supervised strategies + reinforcement learning.</li>\n    <li>Network security using anomaly detection + classification.</li>\n  </ul>\n\n  <h2 style=\"color:#ffcc80;margin-top:20px;\">📂 Our Tutorial Dataset — SMS Spam Collection</h2>\n  <p style=\"margin-bottom:15px;\">\n    This dataset (<strong style=\"color:#81d4fa;\">~500 KB</strong>) contains spam and ham (not spam) SMS messages.<br>\n    <strong>Why it’s perfect:</strong> Tiny size, cleans easily, trains fast, and the task is relatable.\n  </p>\n\n  <h2 style=\"color:#ffcc80;margin-top:20px;\">🛠 Hybrid Plan: TF-IDF Model + Keyword Rules</h2>\n  <ol style=\"margin-left:20px;margin-bottom:15px;\">\n    <li><strong style=\"color:#4fc3f7;\">ML Component</strong>\n      <ul>\n        <li>Convert SMS text to numerical vectors with TF-IDF.</li>\n        <li>Train a Logistic Regression or Naive Bayes classifier.</li>\n      </ul>\n    </li>\n    <li><strong style=\"color:#4fc3f7;\">Rule-based Component</strong>\n      <ul>\n        <li>Define a dictionary of common spam words (<em>\"free\", \"win\", \"click\", \"offer\"</em>).</li>\n        <li>If message contains enough triggers → predict spam directly.</li>\n      </ul>\n    </li>\n    <li><strong style=\"color:#4fc3f7;\">Hybrid Decision</strong>\n      <ul>\n        <li>If rules detect high spam risk → final label spam.</li>\n        <li>Else → trust ML model output.</li>\n      </ul>\n    </li>\n  </ol>\n\n  <h2 style=\"color:#ffcc80;margin-top:20px;\">📊 Tutorial Workflow</h2>\n  <ol style=\"margin-left:20px;margin-bottom:15px;\">\n    <li>Dataset exploration — visualize spam vs. ham counts.</li>\n    <li>Baseline ML Model — simple TF-IDF + Logistic Regression.</li>\n    <li>Design keyword rules — experiment with thresholds.</li>\n    <li>Combine outputs — weighted decision or rule priority.</li>\n    <li>Evaluate — compare hybrid vs. pure ML performance.</li>\n    <li>Conclusion — discuss where hybrid wins.</li>\n  </ol>\n\n  <h2 style=\"color:#ffcc80;margin-top:20px;\">💡 Why This Tutorial Works Well</h2>\n  <ul style=\"margin-left:20px;margin-bottom:15px;\">\n    <li>Lightweight — ideal for live demos and quick iteration.</li>\n    <li>Clear step-by-step introduction to hybrid concepts.</li>\n    <li>Real-world relevance — SMS spam filtering is everywhere.</li>\n  </ul>\n\n  <p style=\"margin-top:20px;font-style:italic;color:#b0bec5;\">\n    Tip: Treat Hybrid Learning like mixing coffee and milk ☕ + 🥛 — each can be good alone, but together, they create something smoother.\n  </p>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:#121212;color:#e0e0e0;padding:20px;font-family:Arial,Helvetica,sans-serif;line-height:1.6;border-radius:8px;\">\n  <h2 style=\"color:#ff9800;margin-top:0;\">🔀 Different Ways to Do Hybrid Learning in AI</h2>\n\n  <p style=\"margin-bottom:15px;\">\n    Hybrid learning in AI means <strong style=\"color:#4fc3f7;\">combining two or more methods</strong> to solve a problem more effectively than using them in isolation.\n    Below are popular hybrid strategies:\n  </p>\n\n  <h3 style=\"color:#ffcc80;margin-top:15px;\">1️⃣ ML + Rule-Based Systems</h3>\n  <p>Combine a machine learning model with human‑crafted rules.  \n    <em style=\"color:#b0bec5;\">Example:</em> Spam filter using Naive Bayes + keyword blacklist.\n  </p>\n\n  <h3 style=\"color:#ffcc80;margin-top:15px;\">2️⃣ Supervised + Unsupervised Learning</h3>\n  <p>Unsupervised clustering or representation learning feeds features into a supervised classifier.  \n    <em style=\"color:#b0bec5;\">Example:</em> Customer segmentation via KMeans → segments used for targeted prediction.\n  </p>\n\n  <h3 style=\"color:#ffcc80;margin-top:15px;\">3️⃣ Classical ML + Deep Learning</h3>\n  <p>Use deep learning for feature extraction, then apply classical algorithms for prediction.  \n    <em style=\"color:#b0bec5;\">Example:</em> CNN image embeddings + Random Forest classifier.\n  </p>\n\n  <h3 style=\"color:#ffcc80;margin-top:15px;\">4️⃣ Reinforcement + Supervised Learning</h3>\n  <p>Train a model with supervised learning, then fine‑tune using reinforcement signals.  \n    <em style=\"color:#b0bec5;\">Example:</em> Game AI that learns from human replays before exploring new strategies.\n  </p>\n\n  <h3 style=\"color:#ffcc80;margin-top:15px;\">5️⃣ Multiple Supervised Models (Ensembles)</h3>\n  <p>Blend predictions from different supervised models to improve accuracy and robustness.  \n    <em style=\"color:#b0bec5;\">Example:</em> Random Forest + Gradient Boosting + Neural Network ensemble.\n  </p>\n\n  <p style=\"margin-top:20px;font-style:italic;color:#b0bec5;\">\n    Each hybrid method has trade-offs — the art is knowing which combination fits your data and problem best.\n  </p>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:#121212;color:#e0e0e0;padding:20px;font-family:Arial,Helvetica,sans-serif;line-height:1.6;border-radius:8px;\">\n  <h2 style=\"color:#ff9800;margin-top:0;\">📍 Step 1 — Understanding the Dataset</h2>\n\n  <p style=\"margin-bottom:15px;\">\n    Before building any <strong style=\"color:#4fc3f7;\">Hybrid Learning</strong> model, we first need to\n    understand the shape, quality, and nature of our data.  \n    This step ensures we know exactly what we’re working with — preventing surprises later.\n  </p>\n\n  <h3 style=\"color:#ffcc80;margin-top:15px;\">🔎 What We'll Do Here</h3>\n  <ul style=\"margin-left:20px;margin-bottom:15px;\">\n    <li>Load the <strong>SMS Spam Collection</strong> dataset into a Pandas DataFrame.</li>\n    <li>Inspect the first few rows using <code style=\"background-color:#2e2e2e;color:#81d4fa;padding:2px 6px;border-radius:4px;\">df.head()</code>.</li>\n    <li>Get dataset dimensions with <code style=\"background-color:#2e2e2e;color:#81d4fa;padding:2px 6px;border-radius:4px;\">df.shape</code>.</li>\n    <li>Check class distribution (spam vs. ham) — both counts and percentages.</li>\n    <li>Look at basic descriptive statistics for text lengths.</li>\n    <li>Ensure there are no <strong>missing values</strong> or obviously corrupted entries.</li>\n  </ul>\n\n  <h3 style=\"color:#ffcc80;margin-top:15px;\">💡 Why This Matters</h3>\n  <p style=\"margin-bottom:15px;\">\n    Understanding the dataset's structure and target balance helps us:\n  </p>\n  <ul style=\"margin-left:20px;margin-bottom:15px;\">\n    <li>Spot data quality issues early.</li>\n    <li>Choose the right preprocessing steps.</li>\n    <li>Plan for strategies like resampling when the target classes are imbalanced.</li>\n  </ul>\n\n  <p style=\"margin-top:20px;font-style:italic;color:#b0bec5;\">\n    Think of this step as <em>“reading the recipe before cooking”</em> — you don’t want surprises\n    halfway through the meal!\n  </p>\n</div>\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Load the SMS Spam Collection dataset\n# Adjust the filename/path if needed (Kaggle usually puts it in ../input/)\ndf = pd.read_csv(\"/kaggle/input/sms-spam-collection-dataset/spam.csv\", encoding=\"latin-1\")\n\n# --- Basic Inspection ---\nprint(\"First 5 rows:\")\ndisplay(df.head())\n\n# Dataset dimensions\nprint(f\"\\nShape of dataset: {df.shape}\")\n\n# Remove any unwanted extra columns if they exist\ndf = df[['v1', 'v2']]\ndf.columns = ['label', 'message']\n\n# --- Missing value check ---\nprint(\"\\nMissing values per column:\")\nprint(df.isnull().sum())\n\n# --- Target distribution ---\nlabel_counts = df['label'].value_counts()\nlabel_percent = df['label'].value_counts(normalize=True) * 100\n\nprint(\"\\nLabel distribution (counts):\")\nprint(label_counts)\nprint(\"\\nLabel distribution (percentages):\")\nprint(label_percent.round(2))\n\n# --- Text length statistics ---\ndf['message_length'] = df['message'].apply(len)\nprint(\"\\nMessage length statistics:\")\nprint(df['message_length'].describe())\n\n# Optional: quick sample of messages\nprint(\"\\nRandom sample of ham/spam messages:\")\ndisplay(df.groupby('label').apply(lambda x: x.sample(2, random_state=42))[['label', 'message']])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T16:16:20.804012Z","iopub.execute_input":"2025-09-15T16:16:20.804375Z","iopub.status.idle":"2025-09-15T16:16:20.933363Z","shell.execute_reply.started":"2025-09-15T16:16:20.804351Z","shell.execute_reply":"2025-09-15T16:16:20.932405Z"}},"outputs":[{"name":"stdout","text":"First 5 rows:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"     v1                                                 v2 Unnamed: 2  \\\n0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n1   ham                      Ok lar... Joking wif u oni...        NaN   \n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n3   ham  U dun say so early hor... U c already then say...        NaN   \n4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n\n  Unnamed: 3 Unnamed: 4  \n0        NaN        NaN  \n1        NaN        NaN  \n2        NaN        NaN  \n3        NaN        NaN  \n4        NaN        NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>v1</th>\n      <th>v2</th>\n      <th>Unnamed: 2</th>\n      <th>Unnamed: 3</th>\n      <th>Unnamed: 4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nShape of dataset: (5572, 5)\n\nMissing values per column:\nlabel      0\nmessage    0\ndtype: int64\n\nLabel distribution (counts):\nlabel\nham     4825\nspam     747\nName: count, dtype: int64\n\nLabel distribution (percentages):\nlabel\nham     86.59\nspam    13.41\nName: proportion, dtype: float64\n\nMessage length statistics:\ncount    5572.000000\nmean       80.118808\nstd        59.690841\nmin         2.000000\n25%        36.000000\n50%        61.000000\n75%       121.000000\nmax       910.000000\nName: message_length, dtype: float64\n\nRandom sample of ham/spam messages:\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/3326217996.py:38: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  display(df.groupby('label').apply(lambda x: x.sample(2, random_state=42))[['label', 'message']])\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"           label                                            message\nlabel                                                              \nham   3714   ham  I am late,so call you tomorrow morning.take ca...\n      1311   ham  U r too much close to my heart. If u go away i...\nspam  1455  spam  Summers finally here! Fancy a chat or flirt wi...\n      1852  spam  This is the 2nd time we have tried 2 contact u...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>label</th>\n      <th>message</th>\n    </tr>\n    <tr>\n      <th>label</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">ham</th>\n      <th>3714</th>\n      <td>ham</td>\n      <td>I am late,so call you tomorrow morning.take ca...</td>\n    </tr>\n    <tr>\n      <th>1311</th>\n      <td>ham</td>\n      <td>U r too much close to my heart. If u go away i...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">spam</th>\n      <th>1455</th>\n      <td>spam</td>\n      <td>Summers finally here! Fancy a chat or flirt wi...</td>\n    </tr>\n    <tr>\n      <th>1852</th>\n      <td>spam</td>\n      <td>This is the 2nd time we have tried 2 contact u...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"<div style=\"background-color:#121212;color:#e0e0e0;padding:20px;font-family:Arial,Helvetica,sans-serif;line-height:1.6;border-radius:8px;\">\n  <h2 style=\"color:#ff9800;margin-top:0;\">🔍 Step 1 Insight — Data Overview</h2>\n\n  <p style=\"margin-bottom:15px;\">\n    After loading and taking an initial peek at the <strong style=\"color:#4fc3f7;\">SMS Spam Collection Dataset</strong>,\n    here’s what we observe:\n  </p>\n\n  <h3 style=\"color:#ffcc80;margin-top:15px;\">📊 Target Distribution</h3>\n  <ul style=\"margin-left:20px;margin-bottom:15px;\">\n    <li>Ham messages: <strong>4825</strong> </li>\n    <li>Spam messages: <strong>774</strong> </li>\n    <li>This means the dataset is <strong>imbalanced</strong>, but not severely </li>\n  </ul>\n\n  <h3 style=\"color:#ffcc80;margin-top:15px;\">📜 Sample Messages</h3>\n  <ul style=\"margin-left:20px;margin-bottom:15px;\">\n    <li><strong>Ham:</strong> “I am late, so call you tomorrow morning. Take care.” — casual, personal tone.</li>\n    <li><strong>Spam:</strong> “Summers finally here! Fancy a chat or flirt with me?” — sales/unsolicited tone.</li>\n  </ul>\n\n  <h3 style=\"color:#ffcc80;margin-top:15px;\">📏 Message Length Insights</h3>\n  <ul style=\"margin-left:20px;margin-bottom:15px;\">\n    <li>Ham messages tend to be shorter and conversational.</li>\n    <li>Spam messages often contain promotional content and may be longer.</li>\n    <li>Length statistics will help us design smarter preprocessing (e.g., handling very short or very long outliers).</li>\n  </ul>\n\n  <h3 style=\"color:#ffcc80;margin-top:15px;\">🧹 Data Quality Check</h3>\n  <ul style=\"margin-left:20px;margin-bottom:15px;\">\n    <li>No missing values in either <strong>label</strong> or <strong>message</strong>.</li>\n    <li>Some promotional spam lines may contain repeated or unusual character sequences — worth cleaning if it improves model clarity.</li>\n  </ul>\n\n  <p style=\"margin-top:20px;font-style:italic;color:#b0bec5;\">\n    The dataset is small, clean, and interpretable — perfect for quick experiments and \n    for illustrating <strong>Hybrid Learning</strong> concepts without heavy computation.\n  </p>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:#121212;color:#e0e0e0;padding:20px;font-family:Arial,Helvetica,sans-serif;line-height:1.6;border-radius:8px;\">\n  <h2 style=\"color:#ff9800;margin-top:0;\">🛠 Step 2 — Preprocessing the Data</h2>\n\n  <p style=\"margin-bottom:15px;\">\n    With a clear understanding of our dataset, \n    it’s time to prepare it for the \n    <strong style=\"color:#4fc3f7;\">Hybrid Learning pipeline</strong>.\n    This preprocessing step ensures our text data is \n    normalized, consistent, and ready for both \n    <em>machine learning algorithms</em> and <em>rule‑based filters</em>.\n  </p>\n\n  <h3 style=\"color:#ffcc80;margin-top:15px;\">🔹 Core Preprocessing Steps</h3>\n  <ul style=\"margin-left:20px;margin-bottom:15px;\">\n    <li><strong>Lowercasing:</strong> Standardize text to avoid treating “Free” and “free” as different words.</li>\n    <li><strong>Removing punctuation &amp; special characters:</strong> Clean noise for simpler token matching.</li>\n    <li><strong>Tokenization:</strong> Split SMS text into individual words for ML features and keyword rules.</li>\n    <li><strong>Stopword removal:</strong> Remove common words (e.g., “the”, “is”) that don’t add much meaning.</li>\n    <li><strong>Optional stemming/lemmatization:</strong> Reduce words to their base form (e.g., “winning” → “win”).</li>\n    <li><strong>Create custom features:</strong> Keep <code style=\"background-color:#2e2e2e;color:#81d4fa;padding:2px 6px;border-radius:4px;\">message_length</code> and flag special tokens (currency symbols, numbers, URLs).</li>\n  </ul>\n\n  <h3 style=\"color:#ffcc80;margin-top:15px;\">🔹 Why Preprocessing Matters in Hybrid Learning</h3>\n  <ul style=\"margin-left:20px;margin-bottom:15px;\">\n    <li><em>ML Side:</em> Clean text improves model generalization and speeds up training.</li>\n    <li><em>Rule Side:</em> Consistent text formatting increases accuracy of keyword matching.</li>\n    <li>Preprocessing acts as a bridge — both components use the same “cleaned” view of the message.</li>\n  </ul>\n\n  <h3 style=\"color:#ffcc80;margin-top:15px;\">🔹 Mini‑Workflow</h3>\n  <ol style=\"margin-left:20px;margin-bottom:15px;\">\n    <li>Load clean text column.</li>\n    <li>Apply all preprocessing transformations.</li>\n    <li>Store both <em>raw</em> and <em>processed</em> forms — raw for human readability, processed for algorithms.</li>\n  </ol>\n\n  <p style=\"margin-top:20px;font-style:italic;color:#b0bec5;\">\n    Imagine sending a resume — you remove typos, irrelevant details, \n    and make it neat. Preprocessing does the same for data \n    before showing it to your AI model.\n  </p>\n</div>\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport string\nimport re\nimport nltk\n\n# Download stopwords if not already available\nnltk.download(\"stopwords\")\nfrom nltk.corpus import stopwords\n\n# Define English stopwords\nstop_words = set(stopwords.words(\"english\"))\n\n# --- Lowercase, remove punctuation, tokenize, remove stopwords ---\ndef preprocess_text(text):\n    # Lowercase\n    text = text.lower()\n    # Remove punctuation\n    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n    # Remove numbers and URLs\n    text = re.sub(r\"http\\S+|www\\S+|[\\d]+\", \"\", text)\n    # Tokenize (simple split)\n    tokens = text.split()\n    # Remove stopwords\n    tokens = [word for word in tokens if word not in stop_words]\n    return \" \".join(tokens)\n\n# Apply preprocessing to a new column\ndf[\"clean_message\"] = df[\"message\"].apply(preprocess_text)\n\n# Message length and advanced features\ndf[\"message_length\"] = df[\"message\"].apply(len)\ndf[\"num_digits\"] = df[\"message\"].apply(lambda x: sum(ch.isdigit() for ch in x))\ndf[\"num_special_chars\"] = df[\"message\"].apply(lambda x: sum(not ch.isalnum() and not ch.isspace() for ch in x))\n\n# --- Quick preview ---\nprint(\"Original message vs cleaned version:\")\ndisplay(df[[\"message\", \"clean_message\"]].head(5))\n\nprint(\"\\nBasic stats for engineered features:\")\nprint(df[[\"message_length\", \"num_digits\", \"num_special_chars\"]].describe())\n\n# --- Sanity check ---\nprint(f\"\\nExample cleaned ham: {df[df.label=='ham'].iloc[0].clean_message}\")\nprint(f\"Example cleaned spam: {df[df.label=='spam'].iloc[0].clean_message}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T16:16:25.300315Z","iopub.execute_input":"2025-09-15T16:16:25.300661Z","iopub.status.idle":"2025-09-15T16:16:25.480111Z","shell.execute_reply.started":"2025-09-15T16:16:25.300625Z","shell.execute_reply":"2025-09-15T16:16:25.479041Z"}},"outputs":[{"name":"stdout","text":"Original message vs cleaned version:\n","output_type":"stream"},{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                             message  \\\n0  Go until jurong point, crazy.. Available only ...   \n1                      Ok lar... Joking wif u oni...   \n2  Free entry in 2 a wkly comp to win FA Cup fina...   \n3  U dun say so early hor... U c already then say...   \n4  Nah I don't think he goes to usf, he lives aro...   \n\n                                       clean_message  \n0  go jurong point crazy available bugis n great ...  \n1                            ok lar joking wif u oni  \n2  free entry wkly comp win fa cup final tkts st ...  \n3                u dun say early hor u c already say  \n4        nah dont think goes usf lives around though  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>message</th>\n      <th>clean_message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>go jurong point crazy available bugis n great ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>ok lar joking wif u oni</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>free entry wkly comp win fa cup final tkts st ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>u dun say early hor u c already say</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>nah dont think goes usf lives around though</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nBasic stats for engineered features:\n       message_length   num_digits  num_special_chars\ncount     5572.000000  5572.000000        5572.000000\nmean        80.118808     2.371859           4.287150\nstd         59.690841     6.244660           4.685449\nmin          2.000000     0.000000           0.000000\n25%         36.000000     0.000000           2.000000\n50%         61.000000     0.000000           3.000000\n75%        121.000000     1.000000           6.000000\nmax        910.000000    47.000000         133.000000\n\nExample cleaned ham: go jurong point crazy available bugis n great world la e buffet cine got amore wat\nExample cleaned spam: free entry wkly comp win fa cup final tkts st may text fa receive entry questionstd txt ratetcs apply overs\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"<div style=\"background-color:#121212;color:#e0e0e0;padding:20px;font-family:Arial,Helvetica,sans-serif;line-height:1.6;border-radius:8px;\">\n  <h2 style=\"color:#ff9800;margin-top:0;\">📊 Step 2 — Preprocessing Results & Insights</h2>\n\n  <p>\n    After applying our <strong style=\"color:#4fc3f7;\">text cleaning pipeline</strong>, \n    the dataset now has a fresh <code style=\"background-color:#2e2e2e;color:#81d4fa;padding:2px 6px;border-radius:4px;\">clean_message</code> column \n    and additional numeric features for <em>message length</em>, <em>digits</em>, and <em>special characters</em>.\n    These will feed both the <em>machine learning model</em> and the <em>rule‑based system</em>.\n  </p>\n\n  <h3 style=\"color:#ffcc80;margin-top:15px;\">🔹 Sample Before & After</h3>\n  <pre style=\"background-color:#1e1e1e;padding:10px;border-radius:6px;color:#c5e1a5;\">\nOriginal: Go until jurong point, crazy.. Available only in ...\nCleaned : go jurong point crazy available bugis n great ...\n  </pre>\n  <pre style=\"background-color:#1e1e1e;padding:10px;border-radius:6px;color:#ef9a9a;\">\nOriginal: Free entry in 2 a wkly comp to win FA Cup final ...\nCleaned : free entry wkly comp win fa cup final tkts st ...\n  </pre>\n  <p style=\"margin-top:8px;\">\n    Notice how punctuation, numbers, and stopwords are stripped, leaving \n    only the most important tokens.\n  </p>\n\n  <h3 style=\"color:#ffcc80;margin-top:15px;\">🔹 Numeric Feature Insights</h3>\n  <ul style=\"margin-left:20px;margin-bottom:15px;\">\n    <li>📏 <strong>Message length:</strong> Ranges from just 2 characters to a whopping 910, with an average of ~80 characters.</li>\n    <li>🔢 <strong>Digits:</strong> Spam messages often contain more numbers (e.g., phone numbers, prize amounts).</li>\n    <li>❗ <strong>Special characters:</strong> Around 4 on average, but can spike in promotional or unusual spam texts.</li>\n  </ul>\n\n  <h3 style=\"color:#ffcc80;margin-top:15px;\">🔹 Strategic Takeaways</h3>\n  <ul style=\"margin-left:20px;\">\n    <li><em>Machine Learning boost:</em> Cleaned tokens improve TF‑IDF quality by removing noise.</li>\n    <li><em>Rule‑based boost:</em> Easier to match keywords like “free” or “win” when case and punctuation are standardized.</li>\n    <li><em>Engineering extras:</em> Numeric features like <code>num_digits</code> will help detect \n      number-heavy spam patterns.</li>\n  </ul>\n\n  <p style=\"margin-top:20px;font-style:italic;color:#b0bec5;\">\n    We’ve essentially taken raw, messy SMS text and turned it into \n    a neatly trimmed, easier‑to‑analyze buffet for our hybrid model. Next, \n    it’s time to feed this into the baseline machine learning model.\n  </p>\n</div>\n","metadata":{}}]}